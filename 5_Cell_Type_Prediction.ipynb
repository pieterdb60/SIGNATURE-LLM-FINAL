{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Cell Type Prediction\n",
    "\n",
    "In this tutorial, we will demonstrate how to use a pretrained Cell2Sentence (C2S) model to perform cell type prediction on single-cell RNA sequencing datasets. Cell type prediction is a crucial step in single-cell analysis, allowing researchers to identify and classify different cell populations within a dataset. By leveraging the power of C2S models, we can make accurate predictions based on the information encoded in cell sentences.\n",
    "\n",
    "In this tutorial, you will:\n",
    "1. Load the PBMC 3K dataset from 10x (preprocessed in tutorial notebook 1)\n",
    "2. Load a pretrained C2S model that is capable of making cell type predictions.\n",
    "3. Use the model to predict cell types based on the cell sentences derived from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by importing the necessary libraries. These include Python's built-in libraries, third-party libraries for handling numerical computations, progress tracking, and specific libraries for single-cell RNA sequencing data and C2S operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python built-in libraries\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Single-cell libraries\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "\n",
    "# Cell2Sentence imports\n",
    "import cell2sentence as cs\n",
    "from cell2sentence.tasks import predict_cell_types_of_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "Next, we will load the preprocessed dataset from the tutorial 0. This dataset has already been filtered and normalized, so it it ready for transformation into cell sentences.\n",
    "\n",
    "<font color='red'>Please make sure you have completed the preprocessing steps in Tutorial 0 before running the following code, if you are using your own dataset.</font>. Ensure that the file path is correctly set in <font color='gold'>DATA_PATH</font> to where your preprocessed data was saved from tutorial 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data/pbmc3k_final.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = anndata.read_h5ad(DATA_PATH)\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata.var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=\"cell_type\",\n",
    "    size=8,\n",
    "    title=\"PBMC 3K UMAP\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell2Sentence Conversion\n",
    "\n",
    "In this section, we will transform our AnnData object containing our single-cell dataset into a Cell2Sentence (C2S) dataset by calling the functions of the CSData class in the C2S code base. Full documentation for the functions of the CSData class can be found in the documentation page of C2S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_obs_cols_to_keep = [\"cell_type\",\"organism\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSData object\n",
    "arrow_ds, vocabulary = cs.CSData.adata_to_arrow(\n",
    "    adata=adata, \n",
    "    random_state=SEED, \n",
    "    sentence_delimiter=' ',\n",
    "    label_col_names=adata_obs_cols_to_keep\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise we will consider the top 100 genes of the cell sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100  # replace with your desired number of genes\n",
    "\n",
    "arrow_ds = arrow_ds.map(lambda x: {\"cell_sentence\": \" \".join(x[\"cell_sentence\"].split()[:k])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 2000\n",
    "len(arrow_ds[sample_idx]['cell_sentence'].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2s_save_dir = \"./c2s_api_testing\"  # C2S dataset will be saved into this directory\n",
    "c2s_save_name = \"PBMC_3K_tutorial3\"  # This will be the name of our C2S dataset on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_data = cs.CSData.csdata_from_arrow(\n",
    "    arrow_dataset=arrow_ds, \n",
    "    vocabulary=vocabulary,\n",
    "    save_dir=c2s_save_dir,\n",
    "    save_name=c2s_save_name,\n",
    "    dataset_backend=\"arrow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cs_data.get_sentence_strings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we will leave off creating our CSData object until after we load our C2S model. This is because along with the model checkpoint, we saved the indices of train, val, and test set cells, which will allow us to select out test set cells for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load C2S Model\n",
    "\n",
    "Now, we will load a C2S model with which we will do cell type annotation. For this tutorial, this model will be the last checkpoint of the training session from <font color=\"red\">tutorial notebook 4</font>, where we finetuned our cell type prediction model to do cell type prediction specifically on our immune tissue dataset. We will load the last checkpoint saved from training, and specify the same save_dir as we used before during training.\n",
    "- <font color=\"red\">Note:</font> If you are using your own data for this tutorial, make sure to switch out to the model checkpoint which you saved in tutorial notebook 3.\n",
    "- If you want to annotate cell types without finetuning your own C2S model, then tutorial notebook 6 demonstrates how to load the C2S-Pythia-410M cell type prediction foundation model and use it to predict cell types without any finetuning.\n",
    "\n",
    "We can define our CSModel object with our pretrained cell type prediction model as follows, specifying the same save_dir as we used in tutorial 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CSModel object\n",
    "cell_type_prediction_model_path = \"./c2s_api_testing/csmodel_tutorial_3/2025-04-03-14_05_10_finetune_cell_type_prediction/checkpoint-330\"\n",
    "\n",
    "#save_dir = \"/home/sr2464/palmer_scratch/C2S_Files_Syed/c2s_api_testing/csmodel_tutorial_3\"\n",
    "save_dir = \"./c2s_api_testing/csmodel_tutorial_3\"\n",
    "\n",
    "save_name = \"cell_type_pred_pythia_410M_2\"\n",
    "csmodel = cs.CSModel(\n",
    "    model_name_or_path=cell_type_prediction_model_path,\n",
    "    save_dir=save_dir,\n",
    "    save_name=save_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also load the data split indices saved alongside the C2S model checkpoint, so that we know which cells were part of the training and validation set. We will do inference on unseen test set cells, which are 10% of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/\".join(cell_type_prediction_model_path.split(\"/\")[:-1])\n",
    "print(cell_type_prediction_model_path)\n",
    "print(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(base_path, 'data_split_indices_dict.pkl'), 'rb') as f:\n",
    "    data_split_indices_dict = pickle.load(f)\n",
    "data_split_indices_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_split_indices_dict[\"train\"]))\n",
    "print(len(data_split_indices_dict[\"val\"]))\n",
    "print(len(data_split_indices_dict[\"test\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select out test set cells from full arrow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = arrow_ds.select(data_split_indices_dict[\"test\"])\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create our CSData object using only the test set cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c2s_save_dir = \"/home/sr2464/palmer_scratch/C2S_Files_Syed/c2s_api_testing\"  # C2S dataset will be saved into this directory\n",
    "c2s_save_dir = \"./c2s_api_testing\"  # C2S dataset will be saved into this directory\n",
    "\n",
    "c2s_save_name = \"PBMC_3K_tutorial4\"  # This will be the name of our C2S dataset on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csdata = cs.CSData.csdata_from_arrow(\n",
    "    arrow_dataset=test_ds, \n",
    "    vocabulary=vocabulary,\n",
    "    save_dir=c2s_save_dir,\n",
    "    save_name=c2s_save_name,\n",
    "    dataset_backend=\"arrow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(csdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict cell types\n",
    "\n",
    "Now that we have loaded our finetuned cell type prediction model and have our test set, we will do cell type prediction inference using our C2S model. We can use the function predict_cell_types_of_data() from the tasks.py, which will take a CSModel() object and apply it to do cell type prediction on a CSData() object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_cell_types = predict_cell_types_of_data(\n",
    "    csdata=csdata,\n",
    "    csmodel=csmodel,\n",
    "    n_genes=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicted_cell_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_cell_types[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_correct = 0.0\n",
    "for model_pred, gt_label in zip(predicted_cell_types, test_ds[\"cell_type\"]):\n",
    "    # C2S might predict a period at the end of the cell type, which we remove\n",
    "    if model_pred[-1] == \".\":\n",
    "        model_pred = model_pred[:-1]\n",
    "    \n",
    "    if model_pred == gt_label:\n",
    "        total_correct += 1\n",
    "\n",
    "accuracy = total_correct / len(predicted_cell_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(0, 100, 10):\n",
    "    print(\"Model pred: {}, GT label: {}\".format(predicted_cell_types[idx], test_ds[idx][\"cell_type\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our model achieves high accuracy, correctly predicting the cell type of unseen cells from the immune tissue data 83% of the time! The model learned to predict cell type annotations in natural language effectively from a short finetuning period on the new data.\n",
    "\n",
    "\n",
    "[Go to Notebook 6 →](./6_Synthetic_Cell_Generation.ipynb) for some, well, advanced use cases like the generation of synthetic cells."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell2sentence_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
