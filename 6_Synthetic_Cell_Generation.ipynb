{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Advanced Use Cases & Troubleshooting\n",
    "\n",
    "In this final notebook, we'll explore:\n",
    "1. Synthetic cell generation.\n",
    "2. Common troubleshooting tips.\n",
    "\n",
    "## 6.1. Generating Synthetic Cells\n",
    "We can prompt the model to create a new cell's gene list based on a desired cell type. This can help with data augmentation or exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by importing the necessary libraries. These include Python's built-in libraries, third-party libraries for handling numerical computations, progress tracking, and specific libraries for single-cell RNA sequencing data and C2S operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python built-in libraries\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Single-cell libraries\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "\n",
    "# Cell2Sentence imports\n",
    "import cell2sentence as cs\n",
    "from cell2sentence.tasks import generate_cells_conditioned_on_cell_type\n",
    "from cell2sentence.utils import (\n",
    "    post_process_generated_cell_sentences,\n",
    "    reconstruct_expression_from_cell_sentence\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "Next, we will load the preprocessed dataset from the tutorial 0. This dataset has already been filtered and normalized, so it it ready for transformation into cell sentences.\n",
    "\n",
    "<font color='red'>Please make sure you have completed the preprocessing steps in Tutorial 0 before running the following code, if you are using your own dataset.</font>. Ensure that the file path is correctly set in <font color='gold'>DATA_PATH</font> to where your preprocessed data was saved from tutorial 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data/pbmc3k_final.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = anndata.read_h5ad(DATA_PATH)\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata.var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=\"cell_type\",\n",
    "    size=8,\n",
    "    title=\"PBMC 3K UMAP\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell2Sentence Conversion\n",
    "\n",
    "In this section, we will transform our AnnData object containing our single-cell dataset into a Cell2Sentence (C2S) dataset by calling the functions of the CSData class in the C2S code base. Full documentation for the functions of the CSData class can be found in the documentation page of C2S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_obs_cols_to_keep = [\"cell_type\",\"organism\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSData object\n",
    "arrow_ds, vocabulary = cs.CSData.adata_to_arrow(\n",
    "    adata=adata, \n",
    "    random_state=SEED, \n",
    "    sentence_delimiter=' ',\n",
    "    label_col_names=adata_obs_cols_to_keep\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise we will consider the top 100 genes of the cell sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100  # replace with your desired number of genes\n",
    "\n",
    "arrow_ds = arrow_ds.map(lambda x: {\"cell_sentence\": \" \".join(x[\"cell_sentence\"].split()[:k])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 2000\n",
    "len(arrow_ds[sample_idx]['cell_sentence'].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2s_save_dir = \"./c2s_api_testing\"  # C2S dataset will be saved into this directory\n",
    "c2s_save_name = \"PBMC_3K_tutorial3\"  # This will be the name of our C2S dataset on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_data = cs.CSData.csdata_from_arrow(\n",
    "    arrow_dataset=arrow_ds, \n",
    "    vocabulary=vocabulary,\n",
    "    save_dir=c2s_save_dir,\n",
    "    save_name=c2s_save_name,\n",
    "    dataset_backend=\"arrow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cs_data.get_sentence_strings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we will leave off creating our CSData object until after we load our C2S model. This is because along with the model checkpoint, we saved the indices of train, val, and test set cells, which will allow us to select out test set cells for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load C2S Model\n",
    "\n",
    "Now, we will load a C2S model with which we will do cell type annotation. For this tutorial, this model will be the last checkpoint of the training session from <font color=\"red\">tutorial notebook 4</font>, where we finetuned our cell type prediction model to do cell type prediction specifically on our immune tissue dataset. We will load the last checkpoint saved from training, and specify the same save_dir as we used before during training.\n",
    "- <font color=\"red\">Note:</font> If you are using your own data for this tutorial, make sure to switch out to the model checkpoint which you saved in tutorial notebook 3.\n",
    "- If you want to annotate cell types without finetuning your own C2S model, then tutorial notebook 6 demonstrates how to load the C2S-Pythia-410M cell type prediction foundation model and use it to predict cell types without any finetuning.\n",
    "\n",
    "We can define our CSModel object with our pretrained cell type prediction model as follows, specifying the same save_dir as we used in tutorial 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CSModel object\n",
    "cell_type_prediction_model_path = \"./c2s_api_testing/csmodel_tutorial_3/2025-04-03-14_05_10_finetune_cell_type_prediction/checkpoint-330\"\n",
    "\n",
    "#save_dir = \"/home/sr2464/palmer_scratch/C2S_Files_Syed/c2s_api_testing/csmodel_tutorial_3\"\n",
    "save_dir = \"./c2s_api_testing/csmodel_tutorial_3\"\n",
    "\n",
    "save_name = \"cell_type_pred_pythia_410M_2\"\n",
    "csmodel = cs.CSModel(\n",
    "    model_name_or_path=cell_type_prediction_model_path,\n",
    "    save_dir=save_dir,\n",
    "    save_name=save_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also load the data split indices saved alongside the C2S model checkpoint, so that we know which cells were part of the training and validation set. We will do inference on unseen test set cells, which are 10% of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/\".join(cell_type_prediction_model_path.split(\"/\")[:-1])\n",
    "print(cell_type_prediction_model_path)\n",
    "print(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(base_path, 'data_split_indices_dict.pkl'), 'rb') as f:\n",
    "    data_split_indices_dict = pickle.load(f)\n",
    "data_split_indices_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_split_indices_dict[\"train\"]))\n",
    "print(len(data_split_indices_dict[\"val\"]))\n",
    "print(len(data_split_indices_dict[\"test\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select out test set cells from full arrow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = arrow_ds.select(data_split_indices_dict[\"test\"])\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we do not need to create a CSData object. We can simply supply cell types from our test dataset to the cell generation function from tasks.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate cells conditioned on cell type\n",
    "\n",
    "Now that we have loaded our finetuned cell generation model and have our test set cells, we will generate cells using the generate_cells_conditioned_on_cell_type() function from tasks.py, which takes as input a C2S model object as well as a list of cell type to prompt C2S to generate. The function will return 1 generated cell sentences for each cell type supplied, and will handle prompt formatting for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types_to_generate = test_ds[\"cell_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cell_types_to_generate))\n",
    "cell_types_to_generate[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_cells = generate_cells_conditioned_on_cell_type(\n",
    "    csmodel=csmodel, \n",
    "    cell_types_list=cell_types_to_generate, \n",
    "    n_genes=100, \n",
    "    organism=\"Homo sapiens\",\n",
    "    inference_batch_size=inference_batch_size,\n",
    "    max_num_tokens=1024,\n",
    "    use_flash_attn=False,  # at smaller sequence lengths (< 1024), flash attention doesn't significantly benefit text generation.\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the function has generated 264 cells given the cell types which we provided it, mimicing the cell type frequency in the real test set. We can save our generated cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(generated_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/pieterdb/SIGNATURE-Workshop/c2s_api_testing/generated_cells.pkl', 'wb') as f:\n",
    "    pickle.dump(generated_cells, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we view a few of our generated cell sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_cells[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model outputs a string of gene symbols in rank order. You can check if known CD4 T cell markers appear near the top.\n",
    "\n",
    "### Converting Synthetic Sentences Back to Expression\n",
    "C2S includes methods to approximate expression levels from ranks, although it's somewhat experimental. You can use `c2s.transforms.rank_to_expression(...)`. We'll skip a full demo here, but see the official docs for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Troubleshooting\n",
    "1. **Slow inference**: Use a smaller model, ensure GPU usage if possible.\n",
    "2. **Weird or unknown labels**: The model might not have learned that cell type. Double-check gene name formats. Possibly switch to a specialized model or do partial fine-tuning.\n",
    "3. **Out-of-memory**: Reduce batch size, use GPU with larger memory, or use a smaller model.\n",
    "4. **Installation errors**: Make sure `pip install cell2sentence` succeeded; check Python version.\n",
    "\n",
    "## That's It!\n",
    "You've completed a tour of Cell2Sentence for single-cell data. Feel free to experiment further and share feedback or questions.\n",
    "\n",
    "*Happy analyzing your scRNA-seq data with LLMs!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell2sentence_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
